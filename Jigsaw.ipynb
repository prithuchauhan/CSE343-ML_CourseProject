{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Combine toxicity labels\n",
    "data['is_toxic'] = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  is_toxic  \n",
       "0             0        0       0       0              0         0  \n",
       "1             0        0       0       0              0         0  \n",
       "2             0        0       0       0              0         0  \n",
       "3             0        0       0       0              0         0  \n",
       "4             0        0       0       0              0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\prith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    text = text.lower()\n",
    "  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "data['comment_text'] = data['comment_text'].apply(preprocess_text)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['comment_text'], data['is_toxic'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31915,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140030    grandma terri burn trash grandma terri trash h...\n",
       "159124    may utc would easiest admit member involved po...\n",
       "60006     objectivity discussion doubtful nonexistent in...\n",
       "65432                             shelly shock shelly shock\n",
       "154979    care refer ong teng cheong talk page la goutte...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119105    geez forgetful weve already discussed marx ana...\n",
       "131631    carioca rfa thanks support request adminship f...\n",
       "125326                     birthday worry enjoy ur daytalke\n",
       "111256    pseudoscience category im assuming article pse...\n",
       "83590     phrase exists would provided search engine eve...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))  \n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy: 0.9573241422528591\n",
      "F1 Score: 0.7632950990615223\n",
      "ROC AUC: 0.8329951069966297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.9482688391038696\n",
      "F1 Score: 0.6770975943672991\n",
      "ROC AUC: 0.7643936336552688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nb))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron\n",
      "Accuracy: 0.9368322105592981\n",
      "F1 Score: 0.7047451669595782\n",
      "ROC AUC: 0.850295064794137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perc = Perceptron(random_state=42)\n",
    "perc.fit(X_train_tfidf, y_train)\n",
    "y_pred_perc = perc.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Perceptron\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_perc))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_perc))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_perc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.9574181419395269\n",
      "F1 Score: 0.751417596488019\n",
      "ROC AUC: 0.813637234717896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prith\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy: 0.9426915243615854\n",
      "F1 Score: 0.7117415287628053\n",
      "ROC AUC: 0.8333258609160148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_dt))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prith\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier (Hard Voting)\n",
      "Accuracy: 0.9598934670217766\n",
      "F1 Score: 0.775201966982789\n",
      "ROC AUC: 0.8359287296533604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "perc = Perceptron(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('Random Forest', rf),\n",
    "    ('Logistic Regression', lr),\n",
    "    ('Perceptron', perc)\n",
    "], voting='hard')  \n",
    "\n",
    "voting_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_voting = voting_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Voting Classifier (Hard Voting)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_voting))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prith\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Accuracy: 0.9504934983550055\n",
      "F1 Score: 0.7125181950509463\n",
      "ROC AUC: 0.7966607842077266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=2),  \n",
    "    n_estimators=50,  \n",
    "    learning_rate=1,  \n",
    "    random_state=42\n",
    ")\n",
    "adaboost.fit(X_train_tfidf, y_train)\n",
    "y_pred_adaboost = adaboost.predict(X_test_tfidf)\n",
    "\n",
    "print(\"AdaBoost\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_adaboost))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_adaboost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prith\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'learning_rate': 1, 'base_estimator__min_samples_split': 5, 'base_estimator__max_depth': 3}\n",
      "Best F1 Score: 0.7346077465027278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'base_estimator__max_depth': [1, 2, 3],\n",
    "    'base_estimator__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Reduce to 10 combinations\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=adaboost,\n",
    "    param_distributions=param_dist,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_iter=10,  # Reduce to 10 combinations\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2  # Enables detailed progress\n",
    ")\n",
    "\n",
    "# Fit the random search\n",
    "random_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best model\n",
    "best_adaboost = random_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned AdaBoost\n",
      "Accuracy: 0.9529061569794768\n",
      "F1 Score: 0.7400103788271924\n",
      "ROC AUC: 0.8227447620935\n"
     ]
    }
   ],
   "source": [
    "y_pred_best_adaboost = best_adaboost.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Tuned AdaBoost\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_adaboost))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best_adaboost))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_best_adaboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['comment_text'].tolist()\n",
    "labels = data['is_toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:03<00:00, 75102.19B/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'BertTokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tokenize and encode text\u001b[39;00m\n\u001b[0;32m      5\u001b[0m max_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 6\u001b[0m encodings \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[0;32m      7\u001b[0m     texts,\n\u001b[0;32m      8\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_seq_length,\n\u001b[0;32m     11\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Features and labels\u001b[39;00m\n\u001b[0;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BertTokenizer' object is not callable"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode text\n",
    "max_seq_length = 100\n",
    "encodings = tokenizer(\n",
    "    texts,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_seq_length,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Features and labels\n",
    "X = encodings['input_ids']\n",
    "attention_masks = encodings['attention_mask']\n",
    "y = torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "masks_train, masks_test = train_test_split(attention_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "train_data = DataLoader(TensorDataset(X_train, masks_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_data = DataLoader(TensorDataset(X_test, masks_test, y_test), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
    "        output = self.fc(hidden[-1])\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "# Model Parameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = 1  # Binary classification\n",
    "pad_idx = tokenizer.pad_token_id\n",
    "\n",
    "# Initialize the model\n",
    "model = LSTMClassifier(vocab_size, embed_dim, hidden_dim, output_dim, pad_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_data:\n",
    "        input_ids, masks, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(input_ids, masks).squeeze(1)\n",
    "        loss = criterion(predictions, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_data:\n",
    "        input_ids, masks, labels = [x.to(device) for x in batch]\n",
    "        predictions = model(input_ids, masks).squeeze(1)\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert predictions to binary\n",
    "all_preds = [1 if p > 0.5 else 0 for p in all_preds]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
